{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:45.286999Z",
     "start_time": "2024-01-29T10:53:45.259306Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open('../data/wizard_of_oz.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbadba9ca534a4a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:45.316743Z",
     "start_time": "2024-01-29T10:53:45.308706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43187\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.lower()\n",
    "raw_text = re.sub('\\d', '$1 ', raw_text)\n",
    "raw_text = re.sub('[^\\w\\s]+', ' ', raw_text)\n",
    "raw_text = re.sub('[_-]', ' ', raw_text)\n",
    "raw_text = re.sub('\\s+', ' ', raw_text)\n",
    "text = np.array(raw_text.split())\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99da0d008df2eb58",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:46.390351Z",
     "start_time": "2024-01-29T10:53:45.318455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43215\n"
     ]
    }
   ],
   "source": [
    "from nltk import download, word_tokenize\n",
    "\n",
    "# download('punkt')\n",
    "\n",
    "text = word_tokenize(raw_text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a64389c0217fd5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:46.394444Z",
     "start_time": "2024-01-29T10:53:46.391123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 4140\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(text)))\n",
    "print('total words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e31ee01c8d4c52",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:46.535070Z",
     "start_time": "2024-01-29T10:53:46.393508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(4140, 13)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "encoder = BinaryEncoder()\n",
    "encoded_words = np.array(encoder.fit_transform(words), dtype=np.int8)\n",
    "np.shape(encoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b632f48b1b56f2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:46.542435Z",
     "start_time": "2024-01-29T10:53:46.538882Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_from_word = dict((w, encoded_words[i]) for i, w in enumerate(words))\n",
    "word_from_encoded = dict((tuple(encoded_words[i]), w) for i, w in enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758e6c498a269a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# cut the text in semi-redundant sequences of 40 characters, in steps of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c09ed0b3d84a73",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:47.628109Z",
     "start_time": "2024-01-29T10:53:46.543746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 14385\n"
     ]
    }
   ],
   "source": [
    "tokens_per_sentence = 60\n",
    "sentences = []\n",
    "\n",
    "encode_word = lambda word: encoded_from_word[word]\n",
    "encode_sentence = np.vectorize(encode_word, otypes=[np.ndarray], signature='()->(n)')\n",
    "\n",
    "for i in range(0, len(text) - tokens_per_sentence, 3):\n",
    "    excerpt = encode_sentence(text[i: i + tokens_per_sentence])\n",
    "    next_word = encode_word(text[i + tokens_per_sentence])\n",
    "    sentences.append((excerpt, next_word))\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85a3c2b62b6951b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:53:47.833470Z",
     "start_time": "2024-01-29T10:53:47.626798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization... (14385, 60, 13) (14385, 13)\n",
      "Vector of 1st letter of 1st sentence: [0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.zeros((len(sentences), tokens_per_sentence, np.shape(encoded_words)[1]), dtype=int)\n",
    "y = np.zeros((len(sentences), np.shape(encoded_words)[1]), dtype=int)\n",
    "print('Vectorization...', np.shape(X), np.shape(y))\n",
    "for row, (sentence, next_word) in enumerate(sentences):\n",
    "    X[row] = sentence\n",
    "    y[row] = next_word\n",
    "\n",
    "print(\"Vector of 1st letter of 1st sentence:\", X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef02e7da1d7fbac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:06:49.985588Z",
     "start_time": "2024-01-29T11:06:49.940624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape\" (type Reshape).\n\nThere must be at most one unknown dimension in output_shape. Received: output_shape=[-1, -1].\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 60, 13, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Input(shape\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mshape(X)[\u001B[38;5;241m1\u001B[39m:]))\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mEmbedding(input_dim\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mshape(y)[\u001B[38;5;241m0\u001B[39m], output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m))\n\u001B[0;32m----> 7\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mReshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)))\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mLSTM(units\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m))\n\u001B[1;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mDropout(rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.7\u001B[39m))\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:204\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 204\u001B[0m   result \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m previous_value  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/layers/reshaping/reshape.py:105\u001B[0m, in \u001B[0;36mReshape._fix_unknown_dimension\u001B[0;34m(self, input_shape, output_shape)\u001B[0m\n\u001B[1;32m    103\u001B[0m         unknown \u001B[38;5;241m=\u001B[39m index\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 105\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    106\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere must be at most one unknown dimension in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    107\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_shape. Received: output_shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    108\u001B[0m         )\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    110\u001B[0m     known \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m dim\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer \"reshape\" (type Reshape).\n\nThere must be at most one unknown dimension in output_shape. Received: output_shape=[-1, -1].\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 60, 13, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from keras import Input, models, layers, losses, optimizers, activations, metrics\n",
    "\n",
    "print('Build model...')\n",
    "model = models.Sequential()\n",
    "model.add(Input(shape=np.shape(X)[1:]))\n",
    "model.add(layers.Embedding(input_dim=np.shape(y)[0], output_dim=64))\n",
    "model.add(layers.Reshape((-1, -1)))\n",
    "model.add(layers.LSTM(units=256))\n",
    "model.add(layers.Dropout(rate=0.7))\n",
    "model.add(layers.Dense(units=64, activation=activations.relu))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "model.add(layers.Dense(units=np.shape(y)[1], activation=activations.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9234846a48221288",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T10:53:47.942638Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=losses.binary_crossentropy, optimizer=optimizers.legacy.RMSprop(learning_rate=0.01), metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fad81c397face2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T10:53:47.943982Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478a0ec88a8776a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T10:53:47.944807Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(text) - tokens_per_sentence - 1)\n",
    "\n",
    "input_sentence = text[start_index: start_index + tokens_per_sentence]\n",
    "\n",
    "print(\" \".join(input_sentence))\n",
    "\n",
    "for i in range(15):\n",
    "    x = np.expand_dims(encode_sentence(input_sentence), axis=0)\n",
    "    x = np.asarray(x).astype(np.int8)\n",
    "\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    \n",
    "    next_index = tuple((1 if value > 0.1 else 0 for value in prediction[0]))\n",
    "    \n",
    "    next_char = word_from_encoded[next_index]\n",
    "    print(next_char)\n",
    "    input_sentence = np.append(np.delete(input_sentence, 0), next_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a98292cab0ad0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T10:53:47.945422Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
