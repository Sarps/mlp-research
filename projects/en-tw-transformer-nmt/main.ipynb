{
 "cells": [
  {
   "cell_type": "code",
   "id": "f913785250771ef3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ],
    "ExecuteTime": {
     "end_time": "2024-02-27T12:05:56.916067Z",
     "start_time": "2024-02-27T12:05:56.680830Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "exports_dir = 'exports/en-tw-transformer-nmt'\n",
    "asset_dir = '../../data/en-tw'\n",
    "training_sample = 1_000\n",
    "num_attention_layers = 4\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:05:56.925006Z",
     "start_time": "2024-02-27T12:05:56.919723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "exports_dir = os.getcwd() + '/' + exports_dir"
   ],
   "id": "e437df31ca35e3d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:05:56.928966Z",
     "start_time": "2024-02-27T12:05:56.925806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date\n",
    "\n",
    "model_plot = f'{exports_dir}/en-tw.png'\n",
    "checkpoint_filepath = exports_dir + f'/checkpoint.weights.{date.today()}.' + '{epoch:02d}-{val_loss:.2f}.keras'\n",
    "checkpoint_filepath_best = exports_dir + '/checkpoint.weights.best.keras'\n",
    "model_file = f'{exports_dir}/models.pkb'"
   ],
   "id": "d874b82ead132c59",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "84390d776c37178a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:05:56.932676Z",
     "start_time": "2024-02-27T12:05:56.930150Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(exports_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "739d82735a5837f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:01.391882Z",
     "start_time": "2024-02-27T12:05:56.937524Z"
    }
   },
   "source": [
    "from archive.lib.language_index import LanguageIndex\n",
    "\n",
    "input_max_timesteps = 128\n",
    "target_max_timesteps = 128\n",
    "\n",
    "inp_lang = LanguageIndex('en', f'{asset_dir}/en.vocabs.json', f'{asset_dir}/en.txt', input_max_timesteps)\n",
    "targ_lang = LanguageIndex('tw', f'{asset_dir}/tw.vocabs.json', f'{asset_dir}/tw.txt', target_max_timesteps)\n",
    "print(inp_lang, '\\n', targ_lang)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageIndex { name: en, tokenizer: <tokenizers.Tokenizer object at 0x15353be00>, vocab_size: 30000 } \n",
      " LanguageIndex { name: tw, tokenizer: <tokenizers.Tokenizer object at 0x12324d800>, vocab_size: 15000 }\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:01.395752Z",
     "start_time": "2024-02-27T12:06:01.392849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_seq2seq_batches(batch_size=32):\n",
    "    \"\"\"\n",
    "    Generates batches of data for sequence-to-sequence models in the format:\n",
    "    ((src_language_inputs, dest_language_inputs), dest_language_targets)\n",
    "    \n",
    "    Args:\n",
    "    - src_language_index (LanguageIndex): An instance of LanguageIndex for the source language.\n",
    "    - dest_language_index (LanguageIndex): An instance of LanguageIndex for the destination language.\n",
    "    - batch_size (int): The number of sequences per batch.\n",
    "    \n",
    "    Yields:\n",
    "    - A tuple of ((src_language_inputs, dest_language_inputs), dest_language_targets) for each batch.\n",
    "    \"\"\"\n",
    "    # Initialize the generators for both source and destination languages\n",
    "    src_generator = inp_lang.data(batch_size=batch_size)\n",
    "    dest_generator = targ_lang.data(batch_size=batch_size)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            src_batch_inputs = next(src_generator)\n",
    "            dest_batch_inputs = next(dest_generator)\n",
    "\n",
    "            dest_batch_targets = np.hstack((dest_batch_inputs[:, 1:], np.zeros((dest_batch_inputs.shape[0], 1))))\n",
    "\n",
    "            yield (src_batch_inputs, dest_batch_inputs), dest_batch_targets\n",
    "\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "# Usage example\n",
    "# Assuming `src_language_index` and `dest_language_index` are instances of LanguageIndex for their respective languages\n",
    "# for ((src_inputs, dest_inputs), dest_targets) in generate_seq2seq_batches(src_language_index, dest_language_index, batch_size=32):\n",
    "#     # Process the batches here, e.g., feed them to a sequence-to-sequence model\n"
   ],
   "id": "4f64d5195bc3144c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:01.974485Z",
     "start_time": "2024-02-27T12:06:01.397197Z"
    }
   },
   "source": [
    "from archive.lib.utils import tf_embedding_scale, create_positional_encoding\n",
    "from archive.lib.layers.dense import FeedForward\n",
    "from archive.lib.layers.attention import SelfAttention, MaskedSelfAttention, CrossAttention\n",
    "from keras import layers\n",
    "from archive.lib.models import graph\n",
    "\n",
    "embed_dim = 512\n",
    "input_vocab_size = 30_000\n",
    "target_vocab_size = 15_000\n",
    "\n",
    "position_vectors = create_positional_encoding(max_seq_len=target_max_timesteps, embed_dim=embed_dim)\n",
    "\n",
    "model = graph.Graph(\n",
    "    inputs=[\n",
    "        layers.Input(shape=(input_max_timesteps,), name='english_input'),\n",
    "        layers.Input(shape=(target_max_timesteps,), name='twi_input')\n",
    "    ],\n",
    "    layers=[\n",
    "        # Encoder Positional Embedding\n",
    "        layers.Embedding(name='encoder_embedding', input_dim=input_vocab_size, output_dim=embed_dim, mask_zero=True),\n",
    "        layers.Lambda(name='encoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='encoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='encoder_dropout', rate=0.1),\n",
    "\n",
    "        SelfAttention(name=\"encoder_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"encoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        # Decoder Positional Embedding\n",
    "        layers.Embedding(name='decoder_embedding', input_dim=target_vocab_size, output_dim=embed_dim,\n",
    "                         mask_zero=True),\n",
    "        layers.Lambda(name='decoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='decoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='decoder_dropout', rate=0.1),\n",
    "\n",
    "        MaskedSelfAttention(name=\"decoder_masked_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        CrossAttention(name=\"decoder_cross_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"decoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        layers.Dense(name='output', units=target_vocab_size)\n",
    "    ],\n",
    "    connections=[\n",
    "        # Encoder\n",
    "        ('english_input', 'encoder_embedding'),\n",
    "        ('encoder_embedding', 'encoder_embeddings_scaled'),\n",
    "        ('encoder_embeddings_scaled', 'encoder_positions'),\n",
    "\n",
    "        ('encoder_positions', 'encoder_dropout'),\n",
    "        ('encoder_dropout', 'encoder_attention'),\n",
    "        ('encoder_attention', 'encoder_feedforward'),\n",
    "\n",
    "        # Bridge - Encoder's output goes to decoder as context\n",
    "        ('encoder_feedforward', 'decoder_cross_attention[context]'),\n",
    "\n",
    "        # Decoder\n",
    "        ('twi_input', 'decoder_embedding'),\n",
    "        ('decoder_embedding', 'decoder_embeddings_scaled'),\n",
    "        ('decoder_embeddings_scaled', 'decoder_positions'),\n",
    "\n",
    "        ('decoder_positions', 'decoder_dropout'),\n",
    "        ('decoder_dropout', 'decoder_masked_attention'),\n",
    "        ('decoder_masked_attention', 'decoder_cross_attention[x]'),\n",
    "        ('decoder_cross_attention', 'decoder_feedforward'),\n",
    "\n",
    "        ('decoder_feedforward', 'output')\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a7ec7c59a0ce4168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:01.989354Z",
     "start_time": "2024-02-27T12:06:01.975242Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english_input (InputLayer)  [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " twi_input (InputLayer)      [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " encoder_embedding (Embeddi  (None, 128, 512)             1536000   ['english_input[0][0]']       \n",
      " ng)                                                      0                                       \n",
      "                                                                                                  \n",
      " decoder_embedding (Embeddi  (None, 128, 512)             7680000   ['twi_input[0][0]']           \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_embeddings_scaled   (None, 128, 512)             0         ['encoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " decoder_embeddings_scaled   (None, 128, 512)             0         ['decoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " encoder_positions (Lambda)  (None, 128, 512)             0         ['encoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " decoder_positions (Lambda)  (None, 128, 512)             0         ['decoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " encoder_dropout (Dropout)   (None, 128, 512)             0         ['encoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_dropout (Dropout)   (None, 128, 512)             0         ['decoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_attention (SelfAtt  (None, 128, 512)             8402432   ['encoder_dropout[0][0]']     \n",
      " ention)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_masked_attention (  (None, 128, 512)             8402432   ['decoder_dropout[0][0]']     \n",
      " MaskedSelfAttention)                                                                             \n",
      "                                                                                                  \n",
      " encoder_feedforward (FeedF  (None, 128, 512)             2100736   ['encoder_attention[0][0]']   \n",
      " orward)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_cross_attention (C  (None, 128, 512)             8402432   ['decoder_masked_attention[0][\n",
      " rossAttention)                                                     0]',                          \n",
      "                                                                     'encoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      " decoder_feedforward (FeedF  (None, 128, 512)             2100736   ['decoder_cross_attention[0][0\n",
      " orward)                                                            ]']                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 128, 15000)           7695000   ['decoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 60143768 (229.43 MB)\n",
      "Trainable params: 60143768 (229.43 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "89fa9db4e2083129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:02.191763Z",
     "start_time": "2024-02-27T12:06:01.990268Z"
    }
   },
   "source": [
    "if os.path.exists(checkpoint_filepath_best):\n",
    "    model.load_weights(checkpoint_filepath_best)\n",
    "    print(\"Loaded checkpoint from\", checkpoint_filepath_best)\n",
    "else:\n",
    "    print(\"No checkpoint at\", checkpoint_filepath_best)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /Users/emmanuelsarpong/Projects/Extra/DataScience/fcc-llm/projects/en-tw-transformer-nmt/exports/en-tw-transformer-nmt/checkpoint.weights.best.keras\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8361375a6cd9a5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:02.200457Z",
     "start_time": "2024-02-27T12:06:02.192531Z"
    }
   },
   "source": [
    "from archive.lib.utils import masked_loss, TransformerLearningRateSchedule\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizers.legacy.Adam(\n",
    "        TransformerLearningRateSchedule(embed_dim), beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:02.202560Z",
     "start_time": "2024-02-27T12:06:02.201190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from keras import utils\n",
    "# \n",
    "# utils.plot_model(model, to_file=f'{exports_dir}/en-tw.png', show_shapes=True, show_layer_names=True,\n",
    "#                  expand_nested=True)"
   ],
   "id": "e259a00b8feba1a6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "99e6070947ce2609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:02.205291Z",
     "start_time": "2024-02-27T12:06:02.203299Z"
    }
   },
   "source": [
    "from keras import callbacks\n",
    "\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True,\n",
    "                                                save_weights_only=True)\n",
    "checkpoint_callback_best = callbacks.ModelCheckpoint(filepath=checkpoint_filepath_best, save_best_only=True,\n",
    "                                                     save_weights_only=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e53870f01b776551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:11.421542Z",
     "start_time": "2024-02-27T12:06:02.206088Z"
    }
   },
   "source": [
    "import itertools\n",
    "\n",
    "train_generator = generate_seq2seq_batches(batch_size)\n",
    "validation_generator = generate_seq2seq_batches(batch_size / 2)\n",
    "itertools.islice(train_generator, 20)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=training_sample / batch_size,\n",
    "    validation_steps=10,\n",
    "    callbacks=[checkpoint_callback_best, checkpoint_callback]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/31 [..............................] - ETA: 2:26 - loss: 9.0019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m validation_generator \u001B[38;5;241m=\u001B[39m generate_seq2seq_batches(batch_size \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      5\u001B[0m itertools\u001B[38;5;241m.\u001B[39mislice(train_generator, \u001B[38;5;241m20\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m      8\u001B[0m     train_generator,\n\u001B[1;32m      9\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m     10\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39mvalidation_generator,\n\u001B[1;32m     11\u001B[0m     steps_per_epoch\u001B[38;5;241m=\u001B[39mtraining_sample \u001B[38;5;241m/\u001B[39m batch_size,\n\u001B[1;32m     12\u001B[0m     validation_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m     13\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m[checkpoint_callback_best, checkpoint_callback]\n\u001B[1;32m     14\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    869\u001B[0m       args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_config\n\u001B[1;32m    870\u001B[0m   )\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[1;32m    141\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall_preflattened(args)\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_flat(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m   1487\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1488\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   1489\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[1;32m   1490\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[1;32m   1491\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1492\u001B[0m   )\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:06:11.422688Z",
     "start_time": "2024-02-27T12:06:11.422634Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4ed2119a6d643628",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
