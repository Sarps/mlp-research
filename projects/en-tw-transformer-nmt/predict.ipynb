{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T19:35:25.881037Z",
     "start_time": "2024-02-25T19:35:22.501912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from archive.lib.models.graph import Graph\n",
    "import archive.lib.utils\n",
    "from archive.lib.layers.attention import BaseAttention, MaskedSelfAttention, SelfAttention, CrossAttention\n",
    "from archive.lib.layers.dense import FeedForward"
   ],
   "id": "e00c06d0fed5a5e8",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function() argument 'code' must be code, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01marchive\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Graph\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01marchive\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01marchive\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mattention\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseAttention, MaskedSelfAttention, SelfAttention, CrossAttention\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01marchive\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdense\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeedForward\n",
      "File \u001B[0;32m~/Projects/Extra/DataScience/fcc-llm/archive/lib/layers/attention.py:16\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mLayerNormalization()\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mAdd()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;129m@register_keras_serializable\u001B[39m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCrossAttention\u001B[39;00m(BaseAttention):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, context):\n\u001B[1;32m     18\u001B[0m         attn_vector, attn_scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmha(query\u001B[38;5;241m=\u001B[39mx, key\u001B[38;5;241m=\u001B[39mcontext, value\u001B[38;5;241m=\u001B[39mcontext, return_attention_scores\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mTypeError\u001B[0m: function() argument 'code' must be code, not str"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T19:35:25.882104Z",
     "start_time": "2024-02-25T19:35:25.882055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exports_dir = '../exports/en-tw-transformer-nmt'\n",
    "model_file = f'{exports_dir}/models.pkb'"
   ],
   "id": "27790ebf3ea3c700",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_translation(sentence, translation):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Prediction\":15s}: {translation}')"
   ],
   "id": "f5837ef57ab08670",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from archive.lib.language_index import LanguageIndex\n",
    "\n",
    "\n",
    "class Translator(tf.Module):\n",
    "    def __init__(self, model: Graph, inp_lang: LanguageIndex, targ_lang: LanguageIndex):\n",
    "        self.transformer = model\n",
    "        self.inp_lang = inp_lang\n",
    "        self.targ_lang = targ_lang\n",
    "\n",
    "    def __call__(self, sentence, max_length=60):\n",
    "        sentence = self.inp_lang.to_padded_tensor([sentence])\n",
    "        output = np.array([self.targ_lang.eos_token])\n",
    "\n",
    "        for i in tf.range(1, max_length):\n",
    "            decoder_input = output[np.newaxis]\n",
    "            predictions = self.transformer.predict([sentence, decoder_input], batch_size=1, verbose=2)\n",
    "            predictions = predictions[:, -1:, :]\n",
    "\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "            output = np.append(output, predicted_id[0], axis=0)\n",
    "\n",
    "            print(\"output\", output)\n",
    "\n",
    "            if predicted_id == self.targ_lang.eos_token:\n",
    "                break\n",
    "\n",
    "        print(np.shape(output[0]))\n",
    "        text = self.targ_lang[output[0].tolist()]\n",
    "\n",
    "        return text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{exports_dir}/en_tw-en.lang.idx\", \"rb\") as input_file:\n",
    "    inp_lang = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{exports_dir}/en_tw-tw.lang.idx\", \"rb\") as input_file:\n",
    "    targ_lang = pickle.load(input_file)\n",
    "\n",
    "with open(model_file, \"rb\") as input_file:\n",
    "    model = pickle.load(input_file)\n",
    "\n",
    "print(inp_lang)\n",
    "print(targ_lang)\n",
    "model.summary()"
   ],
   "id": "f6a7bd6c1fb7388e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translator = Translator(model, inp_lang, targ_lang)",
   "id": "84d9db9700ff818c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from archive.lib.preprocessors.naive_words import naive_words\n",
    "\n",
    "sentence = naive_words(\n",
    "    u\"Lion\",\n",
    "    punctuations=\"?.!,¿'\",\n",
    "    special_chars='ɛƐɔƆ'\n",
    ").split(' ')\n",
    "\n",
    "print_translation(sentence, translator(sentence))"
   ],
   "id": "e988c40349a06661",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
