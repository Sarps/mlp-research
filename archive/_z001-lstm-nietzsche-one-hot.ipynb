{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:38.440457Z",
     "start_time": "2024-01-29T09:43:38.258379Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../data/wizard_of_oz.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99da0d008df2eb58",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:39.618479Z",
     "start_time": "2024-01-29T09:43:38.444044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51652\n"
     ]
    }
   ],
   "source": [
    "from nltk import download, word_tokenize\n",
    "\n",
    "# download('punkt')\n",
    "\n",
    "text = word_tokenize(raw_text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a64389c0217fd5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:39.622508Z",
     "start_time": "2024-01-29T09:43:39.619750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 4719\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(text)))\n",
    "print('total words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e31ee01c8d4c52",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:40.619458Z",
     "start_time": "2024-01-29T09:43:39.621941Z"
    }
   },
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_words = np.array(encoder.fit_transform(words), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b632f48b1b56f2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:40.627424Z",
     "start_time": "2024-01-29T09:43:40.621928Z"
    }
   },
   "outputs": [],
   "source": [
    "index_of_word = dict((w, i) for i, w in enumerate(words))\n",
    "word_from_word = dict((i, w) for i, w in enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758e6c498a269a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### cut the text in semi-redundant sequences of 40 characters, in steps of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c09ed0b3d84a73",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:03:33.212320Z",
     "start_time": "2024-01-29T10:03:33.056612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 17198\n",
      "nb sentence shape (60,)\n"
     ]
    }
   ],
   "source": [
    "tokens_per_sentence = 60\n",
    "sentences = []\n",
    "\n",
    "zeros = np.zeros((len(words)))\n",
    "\n",
    "encode_word = lambda word: index_of_word[word]\n",
    "encode_sentence = lambda sent: np.array([encode_word(word) for _, word in enumerate(sent)])\n",
    "\n",
    "for i in range(0, len(text) - tokens_per_sentence, 3):\n",
    "    excerpt = encode_sentence(text[i: i + tokens_per_sentence])\n",
    "    next_word = encode_word(text[i + tokens_per_sentence])\n",
    "    sentences.append((excerpt, next_word))\n",
    "print('nb sequences:', len(sentences))\n",
    "print('nb sentence shape', np.shape(sentences[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b85a3c2b62b6951b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:06:30.267573Z",
     "start_time": "2024-01-29T10:06:30.254850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization... (17198, 60, 4719) (17198, 4719)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVectorization...\u001B[39m\u001B[38;5;124m'\u001B[39m, np\u001B[38;5;241m.\u001B[39mshape(X), np\u001B[38;5;241m.\u001B[39mshape(y))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row, (sentence, next_word) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sentences):\n\u001B[0;32m----> 7\u001B[0m     X[row, np\u001B[38;5;241m.\u001B[39marange(sentence), sentence] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      8\u001B[0m     y[row, next_word] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVector of 1st letter of 1st sentence:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.zeros((len(sentences), tokens_per_sentence, np.shape(encoded_words)[1]), dtype=int)\n",
    "y = np.zeros((len(sentences), np.shape(encoded_words)[1]), dtype=int)\n",
    "print('Vectorization...', np.shape(X), np.shape(y))\n",
    "for row, (sentence, next_word) in enumerate(sentences):\n",
    "    X[row, np.arange(sentence), sentence] = 1\n",
    "    y[row, next_word] = 1\n",
    "\n",
    "print(\"Vector of 1st letter of 1st sentence:\", X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef02e7da1d7fbac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T09:43:53.358091Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import Input, models, layers, losses, optimizers, activations, metrics\n",
    "\n",
    "print('Build model...')\n",
    "model = models.Sequential()\n",
    "model.add(Input(shape=np.shape(X)[1:]))\n",
    "model.add(layers.LSTM(units=256))\n",
    "model.add(layers.Dropout(rate=0.7))\n",
    "model.add(layers.Dense(units=64, activation=activations.relu))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "model.add(layers.Dense(units=np.shape(y)[1], activation=activations.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9234846a48221288",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:53.360453Z",
     "start_time": "2024-01-29T09:43:53.359649Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=losses.binary_crossentropy, optimizer=optimizers.legacy.RMSprop(learning_rate=0.01), metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fad81c397face2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T09:43:53.360991Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478a0ec88a8776a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T09:43:53.361921Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(text) - tokens_per_sentence - 1)\n",
    "\n",
    "input_sentence = text[start_index: start_index + tokens_per_sentence]\n",
    "\n",
    "print(\" \".join(input_sentence))\n",
    "\n",
    "for i in range(15):\n",
    "    x = np.expand_dims(encode_sentence(input_sentence), axis=0)\n",
    "    x = np.asarray(x).astype(np.int8)\n",
    "\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    \n",
    "    next_index = tuple((1 if value > 0.1 else 0 for value in prediction[0]))\n",
    "    \n",
    "    next_char = word_from_encoded[next_index]\n",
    "    print(next_char)\n",
    "    input_sentence = np.append(np.delete(input_sentence, 0), next_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a98292cab0ad0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:43:53.363437Z",
     "start_time": "2024-01-29T09:43:53.362702Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
