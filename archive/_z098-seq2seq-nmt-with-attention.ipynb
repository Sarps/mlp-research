{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:53.853649Z",
     "start_time": "2024-02-19T18:30:53.814850Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "\n",
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip) + \"/spa-eng/spa.txt\""
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:53.857430Z",
     "start_time": "2024-02-19T18:30:53.854749Z"
    }
   },
   "cell_type": "code",
   "source": "path_to_file",
   "id": "75edb612ae9bbae8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emmanuelsarpong/.keras/datasets/spa-eng/spa.txt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:53.860374Z",
     "start_time": "2024-02-19T18:30:53.857961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = ' ' + w + ' '\n",
    "    return w"
   ],
   "id": "c0a28001d75b8381",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:53.864127Z",
     "start_time": "2024-02-19T18:30:53.861497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from archive.lib.language_index import LanguageIndex\n",
    "\n",
    "\n",
    "def create_dataset(path: str, num_examples: int) -> tuple[List[str], List[str]]:\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(sentence) for sentence in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return [inp for inp, targ in word_pairs], [targ for inp, targ in word_pairs]\n",
    "\n",
    "\n",
    "def load_dataset(path: str, num_examples: int):\n",
    "    en, sp = create_dataset(path, num_examples)\n",
    "\n",
    "    return LanguageIndex([s.split(' ') for s in sp]), LanguageIndex([e.split(' ') for e in en])"
   ],
   "id": "11df0a47f8ab479d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:53.989940Z",
     "start_time": "2024-02-19T18:30:53.864682Z"
    }
   },
   "cell_type": "code",
   "source": "inp_lang, targ_lang = load_dataset(path_to_file, 10000)",
   "id": "7c9ba8f9c5bee8b9",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T18:30:54.026623Z",
     "start_time": "2024-02-19T18:30:53.991369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "    inp_lang.tensor(),\n",
    "    targ_lang.tensor(),\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ],
   "id": "507d1c63638e31ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 8000, 2000, 2000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:44:42.567021Z",
     "start_time": "2024-02-19T21:44:42.561684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import Model, layers\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (batch_size, timesteps) input tensor / sentences\n",
    "        :return: (batch_size, timesteps)\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding(x)  # shape = (batch_size, timesteps, embedding_dim)\n",
    "        sequences, state = self.gru(embeddings)  # shape = (batch_size, timesteps, units), (batch_size, units)\n",
    "        return sequences, state\n"
   ],
   "id": "aa41a722b37c654b",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:44:43.169911Z",
     "start_time": "2024-02-19T21:44:43.164927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = layers.GRU(units, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = layers.Dense(vocab_size)\n",
    "        self.concat = layers.Concatenate(axis=-1)\n",
    "        self.expand_second_axis = layers.Lambda(lambda x: tf.expand_dims(x, 1))\n",
    "\n",
    "        self.attention = layers.Attention()\n",
    "\n",
    "    def call(self, x, enc_sequences, initial_state):\n",
    "        \"\"\"\n",
    "        :param x: (batch_size, 1) Nth word of all the sentences together (batch_size, 1)\n",
    "        :param initial_state: (batch_size, units) Hidden state per sentence (initially from the encoder)\n",
    "        :param enc_sequences: (batch_size, sequence_length, units) Static from encoder with all hidden states in return_sequences=True\n",
    "        :return: (batch_size, seq_len, units)\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding(x)  # shape == (batch_size, 1, embedding_dim)\n",
    "\n",
    "        previous_output = initial_state\n",
    "        previous_output = self.expand_second_axis(previous_output)  # shape == (batch_size, 1, units)\n",
    "\n",
    "        # (batch_size, 1, units), (batch_size, sequence_length, units)\n",
    "        context_vector, attention_weights = self.attention([previous_output, enc_sequences],\n",
    "                                                           return_attention_scores=True)\n",
    "\n",
    "        rnn_input = self.concat([context_vector, embeddings])  # shape == (batch_size, 1, embedding_dim + units)\n",
    "\n",
    "        state = self.gru(rnn_input)  # shape = (batch_size, 1, units), (batch_size, units)\n",
    "        output = self.fc(state)  # shape = (batch_size, vocab_size)\n",
    "\n",
    "        return output, state, attention_weights\n"
   ],
   "id": "20d4eae330b14225",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:44:57.441362Z",
     "start_time": "2024-02-19T21:44:57.422138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "encoder = Encoder(len(inp_lang.word2idx) + 1, embedding_dim, units)\n",
    "decoder = Decoder(len(targ_lang.word2idx) + 1, embedding_dim, units)"
   ],
   "id": "b1725bbcdeb99996",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T23:26:54.235853Z",
     "start_time": "2024-02-19T23:26:54.225752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "optimizer = optimizers.legacy.Adam()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - tf.cast(tf.equal(real, 0), tf.float32)  # Convert boolean mask to float32\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ],
   "id": "bb56ab6060d7721f",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:44:59.733069Z",
     "start_time": "2024-02-19T21:44:59.718046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ],
   "id": "5bcab7aa80a19a63",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:58:25.334354Z",
     "start_time": "2024-02-19T21:50:10.199699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp_sentences, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, hidden = encoder(inp_sentences)\n",
    "            dec_input = targ_lang.zero_idx * tf.ones((BATCH_SIZE, 1))  # Start word [''] of each sentence in the batch\n",
    "\n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                predictions, hidden, _ = decoder(dec_input, enc_output, hidden)\n",
    "\n",
    "                next_words = targ[:, t]  # Next word of each sentence as (BATCH_SIZE)\n",
    "                loss += loss_function(next_words, predictions)\n",
    "                dec_input = tf.expand_dims(next_words, 1)\n",
    "\n",
    "        batch_loss = loss / int(targ.shape[1])\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        variables = encoder.variables + decoder.variables\n",
    "\n",
    "        optimizer.apply_gradients(zip(tape.gradient(loss, variables), variables))\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ],
   "id": "98e9a498b324b96b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.9325\n",
      "Epoch 1 Batch 10 Loss 1.8347\n",
      "Epoch 1 Batch 20 Loss 1.7729\n",
      "Epoch 1 Batch 30 Loss 1.8199\n",
      "Epoch 1 Batch 40 Loss 1.8321\n",
      "Epoch 1 Batch 50 Loss 1.8650\n",
      "Epoch 1 Batch 60 Loss 1.8977\n",
      "Epoch 1 Batch 70 Loss 1.6224\n",
      "Epoch 1 Batch 80 Loss 1.9455\n",
      "Epoch 1 Batch 90 Loss 1.6971\n",
      "Epoch 1 Batch 100 Loss 1.5356\n",
      "Epoch 1 Batch 110 Loss 1.6744\n",
      "Epoch 1 Batch 120 Loss 1.7672\n",
      "Epoch 1 Loss 1.7742\n",
      "Time taken for 1 epoch 49.689882040023804 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4970\n",
      "Epoch 2 Batch 10 Loss 1.5417\n",
      "Epoch 2 Batch 20 Loss 1.7024\n",
      "Epoch 2 Batch 30 Loss 1.6169\n",
      "Epoch 2 Batch 40 Loss 1.5197\n",
      "Epoch 2 Batch 50 Loss 1.5980\n",
      "Epoch 2 Batch 60 Loss 1.5684\n",
      "Epoch 2 Batch 70 Loss 1.5077\n",
      "Epoch 2 Batch 80 Loss 1.4606\n",
      "Epoch 2 Batch 90 Loss 1.5785\n",
      "Epoch 2 Batch 100 Loss 1.4598\n",
      "Epoch 2 Batch 110 Loss 1.5093\n",
      "Epoch 2 Batch 120 Loss 1.5545\n",
      "Epoch 2 Loss 1.5244\n",
      "Time taken for 1 epoch 50.34532308578491 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2945\n",
      "Epoch 3 Batch 10 Loss 1.3567\n",
      "Epoch 3 Batch 20 Loss 1.3384\n",
      "Epoch 3 Batch 30 Loss 1.3351\n",
      "Epoch 3 Batch 40 Loss 1.3086\n",
      "Epoch 3 Batch 50 Loss 1.2539\n",
      "Epoch 3 Batch 60 Loss 1.3276\n",
      "Epoch 3 Batch 70 Loss 1.4520\n",
      "Epoch 3 Batch 80 Loss 1.1902\n",
      "Epoch 3 Batch 90 Loss 1.2675\n",
      "Epoch 3 Batch 100 Loss 1.3274\n",
      "Epoch 3 Batch 110 Loss 1.3707\n",
      "Epoch 3 Batch 120 Loss 1.2887\n",
      "Epoch 3 Loss 1.3252\n",
      "Time taken for 1 epoch 49.032339334487915 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.1434\n",
      "Epoch 4 Batch 10 Loss 1.2392\n",
      "Epoch 4 Batch 20 Loss 1.1627\n",
      "Epoch 4 Batch 30 Loss 1.1730\n",
      "Epoch 4 Batch 40 Loss 1.1867\n",
      "Epoch 4 Batch 50 Loss 1.2015\n",
      "Epoch 4 Batch 60 Loss 1.2759\n",
      "Epoch 4 Batch 70 Loss 1.2596\n",
      "Epoch 4 Batch 80 Loss 1.2929\n",
      "Epoch 4 Batch 90 Loss 1.1822\n",
      "Epoch 4 Batch 100 Loss 1.1986\n",
      "Epoch 4 Batch 110 Loss 1.0213\n",
      "Epoch 4 Batch 120 Loss 1.1575\n",
      "Epoch 4 Loss 1.1474\n",
      "Time taken for 1 epoch 49.53778886795044 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.9045\n",
      "Epoch 5 Batch 10 Loss 0.9311\n",
      "Epoch 5 Batch 20 Loss 0.8908\n",
      "Epoch 5 Batch 30 Loss 0.9458\n",
      "Epoch 5 Batch 40 Loss 0.9460\n",
      "Epoch 5 Batch 50 Loss 1.0295\n",
      "Epoch 5 Batch 60 Loss 0.9998\n",
      "Epoch 5 Batch 70 Loss 0.9159\n",
      "Epoch 5 Batch 80 Loss 1.0953\n",
      "Epoch 5 Batch 90 Loss 0.9442\n",
      "Epoch 5 Batch 100 Loss 0.9553\n",
      "Epoch 5 Batch 110 Loss 1.0123\n",
      "Epoch 5 Batch 120 Loss 0.9693\n",
      "Epoch 5 Loss 0.9885\n",
      "Time taken for 1 epoch 49.39083290100098 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7554\n",
      "Epoch 6 Batch 10 Loss 0.7948\n",
      "Epoch 6 Batch 20 Loss 0.8070\n",
      "Epoch 6 Batch 30 Loss 0.8097\n",
      "Epoch 6 Batch 40 Loss 0.8400\n",
      "Epoch 6 Batch 50 Loss 0.8646\n",
      "Epoch 6 Batch 60 Loss 0.8471\n",
      "Epoch 6 Batch 70 Loss 0.8497\n",
      "Epoch 6 Batch 80 Loss 0.8646\n",
      "Epoch 6 Batch 90 Loss 0.9266\n",
      "Epoch 6 Batch 100 Loss 0.7913\n",
      "Epoch 6 Batch 110 Loss 0.7717\n",
      "Epoch 6 Batch 120 Loss 0.8921\n",
      "Epoch 6 Loss 0.8371\n",
      "Time taken for 1 epoch 49.42067098617554 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6213\n",
      "Epoch 7 Batch 10 Loss 0.7129\n",
      "Epoch 7 Batch 20 Loss 0.6366\n",
      "Epoch 7 Batch 30 Loss 0.7035\n",
      "Epoch 7 Batch 40 Loss 0.6912\n",
      "Epoch 7 Batch 50 Loss 0.7106\n",
      "Epoch 7 Batch 60 Loss 0.6601\n",
      "Epoch 7 Batch 70 Loss 0.6431\n",
      "Epoch 7 Batch 80 Loss 0.7022\n",
      "Epoch 7 Batch 90 Loss 0.6390\n",
      "Epoch 7 Batch 100 Loss 0.7157\n",
      "Epoch 7 Batch 110 Loss 0.6213\n",
      "Epoch 7 Batch 120 Loss 0.6975\n",
      "Epoch 7 Loss 0.6899\n",
      "Time taken for 1 epoch 48.983001708984375 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5875\n",
      "Epoch 8 Batch 10 Loss 0.6164\n",
      "Epoch 8 Batch 20 Loss 0.4799\n",
      "Epoch 8 Batch 30 Loss 0.5414\n",
      "Epoch 8 Batch 40 Loss 0.5170\n",
      "Epoch 8 Batch 50 Loss 0.6322\n",
      "Epoch 8 Batch 60 Loss 0.5634\n",
      "Epoch 8 Batch 70 Loss 0.6421\n",
      "Epoch 8 Batch 80 Loss 0.5287\n",
      "Epoch 8 Batch 90 Loss 0.5809\n",
      "Epoch 8 Batch 100 Loss 0.5653\n",
      "Epoch 8 Batch 110 Loss 0.6003\n",
      "Epoch 8 Batch 120 Loss 0.5220\n",
      "Epoch 8 Loss 0.5646\n",
      "Time taken for 1 epoch 49.38106083869934 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4342\n",
      "Epoch 9 Batch 10 Loss 0.4283\n",
      "Epoch 9 Batch 20 Loss 0.4766\n",
      "Epoch 9 Batch 30 Loss 0.4278\n",
      "Epoch 9 Batch 40 Loss 0.4535\n",
      "Epoch 9 Batch 50 Loss 0.4098\n",
      "Epoch 9 Batch 60 Loss 0.5417\n",
      "Epoch 9 Batch 70 Loss 0.4428\n",
      "Epoch 9 Batch 80 Loss 0.4709\n",
      "Epoch 9 Batch 90 Loss 0.4682\n",
      "Epoch 9 Batch 100 Loss 0.4765\n",
      "Epoch 9 Batch 110 Loss 0.4752\n",
      "Epoch 9 Batch 120 Loss 0.5676\n",
      "Epoch 9 Loss 0.4462\n",
      "Time taken for 1 epoch 49.331382036209106 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.3465\n",
      "Epoch 10 Batch 10 Loss 0.2783\n",
      "Epoch 10 Batch 20 Loss 0.2983\n",
      "Epoch 10 Batch 30 Loss 0.3563\n",
      "Epoch 10 Batch 40 Loss 0.4098\n",
      "Epoch 10 Batch 50 Loss 0.3850\n",
      "Epoch 10 Batch 60 Loss 0.3239\n",
      "Epoch 10 Batch 70 Loss 0.3341\n",
      "Epoch 10 Batch 80 Loss 0.2815\n",
      "Epoch 10 Batch 90 Loss 0.3318\n",
      "Epoch 10 Batch 100 Loss 0.3544\n",
      "Epoch 10 Batch 110 Loss 0.4049\n",
      "Epoch 10 Batch 120 Loss 0.2933\n",
      "Epoch 10 Loss 0.3469\n",
      "Time taken for 1 epoch 50.01240801811218 sec\n",
      "\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T01:40:45.355521Z",
     "start_time": "2024-02-20T01:40:45.314021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import Model, layers, optimizers\n",
    "\n",
    "\n",
    "class Seq2Seq(Model):\n",
    "    def __init__(self, encoder, decoder, sos_token):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sos_token = sos_token\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inp_sentences = inputs[0]\n",
    "        enc_output, enc_hidden = self.encoder(inp_sentences)\n",
    "        dec_input = self.sos_token * tf.ones((inp_sentences.shape[0], 1))\n",
    "\n",
    "        all_predictions = []\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        if training:\n",
    "            targ = inputs[1]\n",
    "            for t in range(targ.shape[1]):\n",
    "                predictions, dec_hidden, _ = self.decoder(dec_input, enc_output, dec_hidden)\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)  # Teacher forcing\n",
    "                all_predictions.append(predictions)\n",
    "        else:\n",
    "            while len(all_predictions) < 100 or all_predictions[-1] == self.sos_token:\n",
    "                predictions, dec_hidden, _ = self.decoder(dec_input, enc_output, dec_hidden)\n",
    "                predicted_id = tf.argmax(predictions, axis=-1)\n",
    "                dec_input = tf.expand_dims(predicted_id, 1)\n",
    "                all_predictions.append(predicted_id)\n",
    "\n",
    "        all_predictions = tf.stack(all_predictions, axis=1)\n",
    "        return all_predictions\n"
   ],
   "id": "7e906d8ea53cb24c",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T01:40:45.960153Z",
     "start_time": "2024-02-20T01:40:45.948422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq2seq_model = Seq2Seq(encoder, decoder, targ_lang.zero_idx)\n",
    "\n",
    "seq2seq_model.compile(optimizer=optimizers.legacy.Adam(), loss=loss_function, metrics=['accuracy'])"
   ],
   "id": "930905bdd4a84a63",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T01:41:15.589120Z",
     "start_time": "2024-02-20T01:40:46.291882Z"
    }
   },
   "cell_type": "code",
   "source": "seq2seq_model.fit([input_tensor_train, target_tensor_train], target_tensor_train, epochs=1, batch_size=BATCH_SIZE)",
   "id": "30c6080afaa78a57",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1708393250.154381       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154533       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154599       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154668       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154741       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154805       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154870       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1708393250.154934       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 29s 195ms/step - loss: 0.0467 - accuracy: 0.7655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x4a15c3950>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T01:43:06.653236Z",
     "start_time": "2024-02-20T01:42:57.726059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "input_seq = sequence.pad_sequences(\n",
    "    [inp_lang[preprocess_sentence(u'tengo hambre').split(' ')]],\n",
    "    maxlen=inp_lang.max_length,\n",
    "    padding='post',\n",
    "    value=inp_lang.zero_idx\n",
    ")\n",
    "\n",
    "predicted_sequences = seq2seq_model.predict([input_seq], verbose=1, batch_size=1)\n",
    "print(type(predicted_sequences[0][0]))\n",
    "\n",
    "output = ' '.join(targ_lang[predicted_sequences[0].tolist()])\n",
    "print(output)"
   ],
   "id": "2d74ae707c0654ea",
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py\", line 73, in tf__call\n        ag__.if_stmt(ag__.ld(training), if_body, else_body, get_state_2, set_state_2, ('dec_hidden', 'dec_input'), 0)\n    File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py\", line 67, in else_body\n        ag__.while_stmt(loop_test, loop_body_1, get_state_1, set_state_1, ('dec_hidden', 'dec_input'), {})\n\n    NotImplementedError: Exception encountered when calling layer 'seq2_seq_31' (type Seq2Seq).\n    \n    in user code:\n    \n        File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/4238803862.py\", line 26, in call  *\n            while len(all_predictions) < 100 or all_predictions[-1] == self.sos_token:\n    \n        NotImplementedError: The condition of while loop started as non-Tensor, then changed to Tensor. This may happen either because variables changed type, or when a break or return statement inside the loop depends on a Tensor condition. In both cases, changing to a TF loop should remove the error.\n        See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#consistency-of-control-flow-types for more info.\n    \n    \n    Call arguments received by layer 'seq2_seq_31' (type Seq2Seq):\n      • inputs=('tf.Tensor(shape=(1, 12), dtype=int32)',)\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[221], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sequence\n\u001B[1;32m      3\u001B[0m input_seq \u001B[38;5;241m=\u001B[39m sequence\u001B[38;5;241m.\u001B[39mpad_sequences(\n\u001B[1;32m      4\u001B[0m     [inp_lang[preprocess_sentence(\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtengo hambre\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)]],\n\u001B[1;32m      5\u001B[0m     maxlen\u001B[38;5;241m=\u001B[39minp_lang\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m      6\u001B[0m     padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      7\u001B[0m     value\u001B[38;5;241m=\u001B[39minp_lang\u001B[38;5;241m.\u001B[39mzero_idx\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m---> 10\u001B[0m predicted_sequences \u001B[38;5;241m=\u001B[39m seq2seq_model\u001B[38;5;241m.\u001B[39mpredict([input_seq], verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(predicted_sequences[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m     13\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(targ_lang[predicted_sequences[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()])\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_file_8q7sp10.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py:73\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m     71\u001B[0m predicted_id \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     72\u001B[0m targ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 73\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mld(training), if_body, else_body, get_state_2, set_state_2, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdec_hidden\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdec_input\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     74\u001B[0m all_predictions \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mstack, (ag__\u001B[38;5;241m.\u001B[39mld(all_predictions),), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py:67\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body\u001B[0;34m()\u001B[0m\n\u001B[1;32m     65\u001B[0m _ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     66\u001B[0m predicted_id \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 67\u001B[0m ag__\u001B[38;5;241m.\u001B[39mwhile_stmt(loop_test, loop_body_1, get_state_1, set_state_1, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdec_hidden\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdec_input\u001B[39m\u001B[38;5;124m'\u001B[39m), {})\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: in user code:\n\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py\", line 73, in tf__call\n        ag__.if_stmt(ag__.ld(training), if_body, else_body, get_state_2, set_state_2, ('dec_hidden', 'dec_input'), 0)\n    File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/__autograph_generated_filen5p8_3nt.py\", line 67, in else_body\n        ag__.while_stmt(loop_test, loop_body_1, get_state_1, set_state_1, ('dec_hidden', 'dec_input'), {})\n\n    NotImplementedError: Exception encountered when calling layer 'seq2_seq_31' (type Seq2Seq).\n    \n    in user code:\n    \n        File \"/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/4238803862.py\", line 26, in call  *\n            while len(all_predictions) < 100 or all_predictions[-1] == self.sos_token:\n    \n        NotImplementedError: The condition of while loop started as non-Tensor, then changed to Tensor. This may happen either because variables changed type, or when a break or return statement inside the loop depends on a Tensor condition. In both cases, changing to a TF loop should remove the error.\n        See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#consistency-of-control-flow-types for more info.\n    \n    \n    Call arguments received by layer 'seq2_seq_31' (type Seq2Seq):\n      • inputs=('tf.Tensor(shape=(1, 12), dtype=int32)',)\n      • training=False\n"
     ]
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 119,
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang):\n",
    "    attention_plot = np.zeros((targ_lang.max_length, inp_lang.max_length))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = tf.convert_to_tensor(\n",
    "        sequence.pad_sequences(\n",
    "            [inp_lang[sentence.split(' ')]],\n",
    "            maxlen=inp_lang.max_length,\n",
    "            padding='post',\n",
    "            value=inp_lang.zero_idx\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    dec_input = targ_lang.zero_idx\n",
    "\n",
    "    enc_sequences, state = encoder(inputs)\n",
    "\n",
    "    for t in range(targ_lang.max_length):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input * tf.ones((1, 1)), enc_sequences, state)\n",
    "\n",
    "        dec_input = int(tf.argmax(predictions[0]).numpy())\n",
    "\n",
    "        result += targ_lang[dec_input] + ' '\n",
    "        attention_plot[t] = tf.reshape(attention_weights, (-1,)).numpy()\n",
    "\n",
    "        if targ_lang[dec_input] == '':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "    return result, sentence, attention_plot"
   ],
   "id": "c2fab4a99b008d4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:00:15.224804Z",
     "start_time": "2024-02-19T21:00:15.220923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='Greys')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ],
   "id": "cbda2229439f1181",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T21:00:17.295283Z",
     "start_time": "2024-02-19T21:00:17.291659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang)\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ],
   "id": "56925a34ae6f4329",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T23:45:44.114180Z",
     "start_time": "2024-02-19T23:45:44.031909Z"
    }
   },
   "cell_type": "code",
   "source": "translate(u'tengo hambre')",
   "id": "48c6ea00a20bcf8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tengo hambre \n",
      "Predicted translation:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/357755776.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/357755776.py:11: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T23:45:46.819375Z",
     "start_time": "2024-02-19T23:45:46.727025Z"
    }
   },
   "cell_type": "code",
   "source": "translate(u'tengo')",
   "id": "548117097db7b316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tengo \n",
      "Predicted translation:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/357755776.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/var/folders/fk/6lvr7z756yjcvwrjfwxbtl8c0000gp/T/ipykernel_65405/357755776.py:11: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "encoder.variables",
   "id": "91a2c55348afe1e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T00:20:10.872959Z",
     "start_time": "2024-02-20T00:20:10.757047Z"
    }
   },
   "cell_type": "code",
   "source": "seq2seq_model.save('../data/output/_z098-seq2seq-nmt-with-attention.keras')",
   "id": "1422e5b1e7441797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:164: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91f0d06eb3d9465f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
