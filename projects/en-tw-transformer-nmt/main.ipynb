{
 "cells": [
  {
   "cell_type": "code",
   "id": "f913785250771ef3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ],
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:26.354866Z",
     "start_time": "2024-02-26T01:47:26.346996Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "exports_dir = 'exports/en-tw-transformer-nmt'\n",
    "training_sample = 100\n",
    "num_attention_layers = 4"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:26.361722Z",
     "start_time": "2024-02-26T01:47:26.357292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "exports_dir = os.getcwd() + '/' + exports_dir"
   ],
   "id": "e437df31ca35e3d5",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:26.366086Z",
     "start_time": "2024-02-26T01:47:26.362685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date\n",
    "\n",
    "model_plot = f'{exports_dir}/en-tw.png'\n",
    "checkpoint_filepath = exports_dir + f'/checkpoint.weights.{date.today()}.' + '{epoch:02d}-{val_loss:.2f}.keras'\n",
    "checkpoint_filepath_best = exports_dir + '/checkpoint.weights.best.keras'\n",
    "model_file = f'{exports_dir}/models.pkb'"
   ],
   "id": "d874b82ead132c59",
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "84390d776c37178a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:26.371842Z",
     "start_time": "2024-02-26T01:47:26.369082Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(exports_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "739d82735a5837f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.125917Z",
     "start_time": "2024-02-26T01:47:26.373142Z"
    }
   },
   "source": [
    "from archive.lib import loaders\n",
    "\n",
    "inp_lang, targ_lang = loaders.en_tw(training_sample)\n",
    "inp_lang.save(exports_dir)\n",
    "targ_lang.save(exports_dir)\n",
    "print(inp_lang, '\\n', targ_lang)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageIndex { sequences: 100, vocab_size: 352, max_sequence_timestep: 35, vocab: ('!', \"'\", ',', '.', '?'...) } \n",
      " LanguageIndex { sequences: 100, vocab_size: 412, max_sequence_timestep: 30, vocab: ('!', \"'\", ',', '.', '?'...) }\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.483795Z",
     "start_time": "2024-02-26T01:47:28.126724Z"
    }
   },
   "source": [
    "from archive.lib.utils import tf_embedding_scale, create_positional_encoding\n",
    "from archive.lib.layers.dense import FeedForward\n",
    "from archive.lib.layers.attention import SelfAttention, MaskedSelfAttention, CrossAttention\n",
    "from keras import layers\n",
    "from archive.lib.models import graph\n",
    "\n",
    "embed_dim = 512\n",
    "max_expected_user_response = 1024\n",
    "\n",
    "position_vectors = create_positional_encoding(max_seq_len=max_expected_user_response, embed_dim=embed_dim)\n",
    "\n",
    "model = graph.Graph(\n",
    "    inputs=[\n",
    "        layers.Input(shape=(inp_lang.max_timesteps,), name='english_input'),\n",
    "        layers.Input(shape=(targ_lang.max_timesteps,), name='twi_input')\n",
    "    ],\n",
    "    layers=[\n",
    "        # Encoder Positional Embedding\n",
    "        layers.Embedding(name='encoder_embedding', input_dim=inp_lang.vocab_size, output_dim=embed_dim, mask_zero=True),\n",
    "        layers.Lambda(name='encoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='encoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='encoder_dropout', rate=0.1),\n",
    "\n",
    "        SelfAttention(name=\"encoder_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"encoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        # Decoder Positional Embedding\n",
    "        layers.Embedding(name='decoder_embedding', input_dim=targ_lang.vocab_size, output_dim=embed_dim,\n",
    "                         mask_zero=True),\n",
    "        layers.Lambda(name='decoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='decoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='decoder_dropout', rate=0.1),\n",
    "\n",
    "        MaskedSelfAttention(name=\"decoder_masked_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        CrossAttention(name=\"decoder_cross_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"decoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        layers.Dense(name='output', units=targ_lang.vocab_size)\n",
    "    ],\n",
    "    connections=[\n",
    "        # Encoder\n",
    "        ('english_input', 'encoder_embedding'),\n",
    "        ('encoder_embedding', 'encoder_embeddings_scaled'),\n",
    "        ('encoder_embeddings_scaled', 'encoder_positions'),\n",
    "\n",
    "        ('encoder_positions', 'encoder_dropout'),\n",
    "        ('encoder_dropout', 'encoder_attention'),\n",
    "        ('encoder_attention', 'encoder_feedforward'),\n",
    "\n",
    "        # Bridge - Encoder's output goes to decoder as context\n",
    "        ('encoder_feedforward', 'decoder_cross_attention[context]'),\n",
    "\n",
    "        # Decoder\n",
    "        ('twi_input', 'decoder_embedding'),\n",
    "        ('decoder_embedding', 'decoder_embeddings_scaled'),\n",
    "        ('decoder_embeddings_scaled', 'decoder_positions'),\n",
    "\n",
    "        ('decoder_positions', 'decoder_dropout'),\n",
    "        ('decoder_dropout', 'decoder_masked_attention'),\n",
    "        ('decoder_masked_attention', 'decoder_cross_attention[x]'),\n",
    "        ('decoder_cross_attention', 'decoder_feedforward'),\n",
    "\n",
    "        ('decoder_feedforward', 'output')\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 35) dtype=float32 (created by layer 'english_input')>, <KerasTensor: shape=(None, 30) dtype=float32 (created by layer 'twi_input')>]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "a7ec7c59a0ce4168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.500911Z",
     "start_time": "2024-02-26T01:47:28.484364Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english_input (InputLayer)  [(None, 35)]                 0         []                            \n",
      "                                                                                                  \n",
      " twi_input (InputLayer)      [(None, 30)]                 0         []                            \n",
      "                                                                                                  \n",
      " encoder_embedding (Embeddi  (None, 35, 512)              180224    ['english_input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_embedding (Embeddi  (None, 30, 512)              210944    ['twi_input[0][0]']           \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_embeddings_scaled   (None, 35, 512)              0         ['encoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " decoder_embeddings_scaled   (None, 30, 512)              0         ['decoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " encoder_positions (Lambda)  (None, 35, 512)              0         ['encoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " decoder_positions (Lambda)  (None, 30, 512)              0         ['decoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " encoder_dropout (Dropout)   (None, 35, 512)              0         ['encoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_dropout (Dropout)   (None, 30, 512)              0         ['decoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_attention (SelfAtt  (None, 35, 512)              8402432   ['encoder_dropout[0][0]']     \n",
      " ention)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_masked_attention (  (None, 30, 512)              8402432   ['decoder_dropout[0][0]']     \n",
      " MaskedSelfAttention)                                                                             \n",
      "                                                                                                  \n",
      " encoder_feedforward (FeedF  (None, 35, 512)              2100736   ['encoder_attention[0][0]']   \n",
      " orward)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_cross_attention (C  (None, 30, 512)              8402432   ['decoder_masked_attention[0][\n",
      " rossAttention)                                                     0]',                          \n",
      "                                                                     'encoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      " decoder_feedforward (FeedF  (None, 30, 512)              2100736   ['decoder_cross_attention[0][0\n",
      " orward)                                                            ]']                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 30, 412)              211356    ['decoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30011292 (114.48 MB)\n",
      "Trainable params: 30011292 (114.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "89fa9db4e2083129",
   "metadata": {},
   "source": [
    "if os.path.exists(checkpoint_filepath):\n",
    "    model.load_weights(checkpoint_filepath)"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "8361375a6cd9a5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.510995Z",
     "start_time": "2024-02-26T01:47:28.505176Z"
    }
   },
   "source": [
    "from archive.lib.utils import masked_loss, TransformerLearningRateSchedule\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizers.legacy.Adam(\n",
    "        TransformerLearningRateSchedule(embed_dim), beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.513457Z",
     "start_time": "2024-02-26T01:47:28.511668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from keras import utils\n",
    "# \n",
    "# utils.plot_model(model, to_file=f'{exports_dir}/en-tw.png', show_shapes=True, show_layer_names=True,\n",
    "#                  expand_nested=True)"
   ],
   "id": "e259a00b8feba1a6",
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "99e6070947ce2609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:28.516116Z",
     "start_time": "2024-02-26T01:47:28.514091Z"
    }
   },
   "source": [
    "from keras import callbacks\n",
    "\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True,\n",
    "                                                save_weights_only=True)\n",
    "checkpoint_callback_best = callbacks.ModelCheckpoint(filepath=checkpoint_filepath_best, save_best_only=True,\n",
    "                                                     save_weights_only=True)"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "e53870f01b776551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:49.330585Z",
     "start_time": "2024-02-26T01:47:28.516754Z"
    }
   },
   "source": [
    "data = inp_lang.tensor(), targ_lang.tensor(shift='start')\n",
    "model.fit(data, targ_lang.tensor(), epochs=10, validation_split=0.2,\n",
    "          callbacks=[checkpoint_callback, checkpoint_callback_best])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 890ms/step - loss: 6.6788 - val_loss: 6.6456\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 680ms/step - loss: 6.6746 - val_loss: 6.6355\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 6.6489 - val_loss: 6.6180\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 6.6488 - val_loss: 6.5934\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 6.6204 - val_loss: 6.5615\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 6.5488 - val_loss: 6.5228\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 6.5120 - val_loss: 6.4766\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 6.4529 - val_loss: 6.4238\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 6.3805 - val_loss: 6.3639\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 2s 886ms/step - loss: 6.3119 - val_loss: 6.2987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2840da350>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "9d397db0ca2ce6a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T01:47:49.663924Z",
     "start_time": "2024-02-26T01:47:49.331981Z"
    }
   },
   "source": [
    "with open(model_file, mode='wb') as f:\n",
    "    pickle.dump(model, f)"
   ],
   "outputs": [],
   "execution_count": 90
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
