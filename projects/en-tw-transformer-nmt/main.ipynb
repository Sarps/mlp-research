{
 "cells": [
  {
   "cell_type": "code",
   "id": "f913785250771ef3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ],
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:32.130559Z",
     "start_time": "2024-02-25T23:50:32.123553Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "exports_dir = 'exports/en-tw-transformer-nmt'\n",
    "training_sample = 100\n",
    "num_attention_layers = 4"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:32.135522Z",
     "start_time": "2024-02-25T23:50:32.132513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "exports_dir = os.getcwd() + '/' + exports_dir"
   ],
   "id": "e437df31ca35e3d5",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:32.138924Z",
     "start_time": "2024-02-25T23:50:32.136356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date\n",
    "\n",
    "model_plot = f'{exports_dir}/en-tw.png'\n",
    "checkpoint_filepath = exports_dir + f'/checkpoint.weights.{date.today()}.' + '{epoch:02d}-{val_loss:.2f}.keras'\n",
    "checkpoint_filepath_best = exports_dir + '/checkpoint.weights.best.keras'\n",
    "model_file = f'{exports_dir}/models.pkb'"
   ],
   "id": "d874b82ead132c59",
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "84390d776c37178a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:32.143Z",
     "start_time": "2024-02-25T23:50:32.140656Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(exports_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "739d82735a5837f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:33.841060Z",
     "start_time": "2024-02-25T23:50:32.143603Z"
    }
   },
   "source": [
    "from archive.lib import loaders\n",
    "\n",
    "inp_lang, targ_lang = loaders.en_tw(training_sample)\n",
    "inp_lang.save(exports_dir)\n",
    "targ_lang.save(exports_dir)\n",
    "print(inp_lang, '\\n', targ_lang)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageIndex { sequences: 100, vocab_size: 352, max_sequence_timestep: 35, vocab: ('!', \"'\", ',', '.', '?'...) } \n",
      " LanguageIndex { sequences: 100, vocab_size: 412, max_sequence_timestep: 30, vocab: ('!', \"'\", ',', '.', '?'...) }\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.199874Z",
     "start_time": "2024-02-25T23:50:33.841759Z"
    }
   },
   "source": [
    "from archive.lib.utils import tf_embedding_scale, create_positional_encoding\n",
    "from archive.lib.layers.dense import FeedForward\n",
    "from archive.lib.layers.attention import SelfAttention, MaskedSelfAttention, CrossAttention\n",
    "from keras import layers\n",
    "from archive.lib.models import graph\n",
    "\n",
    "embed_dim = 512\n",
    "max_expected_user_response = 1024\n",
    "\n",
    "position_vectors = create_positional_encoding(max_seq_len=max_expected_user_response, embed_dim=embed_dim)\n",
    "\n",
    "model = graph.Graph(\n",
    "    inputs=[\n",
    "        layers.Input(shape=(inp_lang.max_timesteps,), name='english_input'),\n",
    "        layers.Input(shape=(targ_lang.max_timesteps,), name='twi_input')\n",
    "    ],\n",
    "    layers=[\n",
    "        # Encoder Positional Embedding\n",
    "        layers.Embedding(name='encoder_embedding', input_dim=inp_lang.vocab_size, output_dim=embed_dim, mask_zero=True),\n",
    "        layers.Lambda(name='encoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='encoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='encoder_dropout', rate=0.1),\n",
    "\n",
    "        SelfAttention(name=\"encoder_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"encoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        # Decoder Positional Embedding\n",
    "        layers.Embedding(name='decoder_embedding', input_dim=targ_lang.vocab_size, output_dim=embed_dim,\n",
    "                         mask_zero=True),\n",
    "        layers.Lambda(name='decoder_embeddings_scaled', function=tf_embedding_scale(embed_dim)),\n",
    "        layers.Lambda(name='decoder_positions',\n",
    "                      function=lambda x: x + position_vectors[:x.shape[0], :x.shape[1], :x.shape[2]]),\n",
    "\n",
    "        layers.Dropout(name='decoder_dropout', rate=0.1),\n",
    "\n",
    "        MaskedSelfAttention(name=\"decoder_masked_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        CrossAttention(name=\"decoder_cross_attention\", num_heads=8, key_dim=embed_dim, dropout=0.1),\n",
    "        FeedForward(name=\"decoder_feedforward\", d_model=embed_dim, dff=2048),\n",
    "\n",
    "        layers.Dense(targ_lang.vocab_size, activation='softmax', name='output')\n",
    "    ],\n",
    "    connections=[\n",
    "        # Encoder\n",
    "        ('english_input', 'encoder_embedding'),\n",
    "        ('encoder_embedding', 'encoder_embeddings_scaled'),\n",
    "        ('encoder_embeddings_scaled', 'encoder_positions'),\n",
    "\n",
    "        ('encoder_positions', 'encoder_dropout'),\n",
    "        ('encoder_dropout', 'encoder_attention'),\n",
    "        ('encoder_attention', 'encoder_feedforward'),\n",
    "\n",
    "        # Bridge - Encoder's output goes to decoder as context\n",
    "        ('encoder_feedforward', 'decoder_cross_attention[context]'),\n",
    "\n",
    "        # Decoder\n",
    "        ('twi_input', 'decoder_embedding'),\n",
    "        ('decoder_embedding', 'decoder_embeddings_scaled'),\n",
    "        ('decoder_embeddings_scaled', 'decoder_positions'),\n",
    "\n",
    "        ('decoder_positions', 'decoder_dropout'),\n",
    "        ('decoder_dropout', 'decoder_masked_attention'),\n",
    "        ('decoder_masked_attention', 'decoder_cross_attention[x]'),\n",
    "        ('decoder_cross_attention', 'decoder_feedforward'),\n",
    "\n",
    "        ('decoder_feedforward', 'output')\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 35) dtype=float32 (created by layer 'english_input')>, <KerasTensor: shape=(None, 30) dtype=float32 (created by layer 'twi_input')>]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "a7ec7c59a0ce4168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.217253Z",
     "start_time": "2024-02-25T23:50:34.200671Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english_input (InputLayer)  [(None, 35)]                 0         []                            \n",
      "                                                                                                  \n",
      " twi_input (InputLayer)      [(None, 30)]                 0         []                            \n",
      "                                                                                                  \n",
      " encoder_embedding (Embeddi  (None, 35, 512)              180224    ['english_input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_embedding (Embeddi  (None, 30, 512)              210944    ['twi_input[0][0]']           \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_embeddings_scaled   (None, 35, 512)              0         ['encoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " decoder_embeddings_scaled   (None, 30, 512)              0         ['decoder_embedding[0][0]']   \n",
      " (Lambda)                                                                                         \n",
      "                                                                                                  \n",
      " encoder_positions (Lambda)  (None, 35, 512)              0         ['encoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " decoder_positions (Lambda)  (None, 30, 512)              0         ['decoder_embeddings_scaled[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " encoder_dropout (Dropout)   (None, 35, 512)              0         ['encoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_dropout (Dropout)   (None, 30, 512)              0         ['decoder_positions[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_attention (SelfAtt  (None, 35, 512)              8402432   ['encoder_dropout[0][0]']     \n",
      " ention)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_masked_attention (  (None, 30, 512)              8402432   ['decoder_dropout[0][0]']     \n",
      " MaskedSelfAttention)                                                                             \n",
      "                                                                                                  \n",
      " encoder_feedforward (FeedF  (None, 35, 512)              2100736   ['encoder_attention[0][0]']   \n",
      " orward)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_cross_attention (C  (None, 30, 512)              8402432   ['decoder_masked_attention[0][\n",
      " rossAttention)                                                     0]',                          \n",
      "                                                                     'encoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      " decoder_feedforward (FeedF  (None, 30, 512)              2100736   ['decoder_cross_attention[0][0\n",
      " orward)                                                            ]']                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 30, 412)              211356    ['decoder_feedforward[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30011292 (114.48 MB)\n",
      "Trainable params: 30011292 (114.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "89fa9db4e2083129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.219703Z",
     "start_time": "2024-02-25T23:50:34.217902Z"
    }
   },
   "source": [
    "if os.path.exists(checkpoint_filepath):\n",
    "    model.load_weights(checkpoint_filepath)"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "8361375a6cd9a5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.230955Z",
     "start_time": "2024-02-25T23:50:34.220309Z"
    }
   },
   "source": [
    "from archive.lib.utils import masked_loss, TransformerLearningRateSchedule\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizers.legacy.Adam(\n",
    "        TransformerLearningRateSchedule(embed_dim), beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.234199Z",
     "start_time": "2024-02-25T23:50:34.232694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from keras import utils\n",
    "# \n",
    "# utils.plot_model(model, to_file=f'{exports_dir}/en-tw.png', show_shapes=True, show_layer_names=True,\n",
    "#                  expand_nested=True)"
   ],
   "id": "e259a00b8feba1a6",
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "99e6070947ce2609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:34.236349Z",
     "start_time": "2024-02-25T23:50:34.234623Z"
    }
   },
   "source": [
    "from keras import callbacks\n",
    "\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True,\n",
    "                                                save_weights_only=True)\n",
    "checkpoint_callback_best = callbacks.ModelCheckpoint(filepath=checkpoint_filepath_best, save_best_only=True,\n",
    "                                                     save_weights_only=True)"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "e53870f01b776551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:53.383297Z",
     "start_time": "2024-02-25T23:50:34.237107Z"
    }
   },
   "source": [
    "data = inp_lang.tensor(), targ_lang.tensor(shift='start')\n",
    "model.fit(data, targ_lang.tensor(), epochs=10, validation_split=0.2,\n",
    "          callbacks=[checkpoint_callback, checkpoint_callback_best])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 782ms/step - loss: 6.6402 - val_loss: 6.5806\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 755ms/step - loss: 6.6123 - val_loss: 6.5698\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 6.6047 - val_loss: 6.5512\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 6.5890 - val_loss: 6.5247\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 6.5520 - val_loss: 6.4907\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 6.4982 - val_loss: 6.4496\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 6.4505 - val_loss: 6.4010\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 6.3841 - val_loss: 6.3457\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 2s 514ms/step - loss: 6.3035 - val_loss: 6.2845\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 2s 515ms/step - loss: 6.2283 - val_loss: 6.2171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x282e0c8d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "9d397db0ca2ce6a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T23:50:53.708140Z",
     "start_time": "2024-02-25T23:50:53.384703Z"
    }
   },
   "source": [
    "with open(model_file, mode='wb') as f:\n",
    "    pickle.dump(model, f)"
   ],
   "outputs": [],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
